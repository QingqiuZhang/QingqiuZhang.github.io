{"posts":[{"title":"Diabetes Dataset Report (2) -- Model Training And Evaluating ","content":"In the previous article, I did data preprocessing. It is often seen as one of the most important step during a machine learning project. One must be patient with the data manimulation no matter how troublesome it is. In this article, we are finally exposed to the model traing procedure. I will demonstrate how to conduct different types of classification models and how to evalute their performance. In case you need the source data, visit this webpage: Data Source Model Training And Evaluating There are so many classification models. Some you may have heard or used while the others not. This articles covers almost all the classification models you may need as a beginner. I will show you how to conduct them and how different hyperparameters will affect the models. K-Nearest Neighbor Classifier Logistic Regression Ordinary Logistic Regression Ridge Lasss Combined Ridge and Lasso Naive Bayes Classifier Support Vector Machine Linear Nonlinear Decision Tree Random Forest ","link":"https://qingqiuzhang.github.io/diabetes-dataset-report-/"},{"title":"Diabetes Dataset Report (1) -- Data Preprocessing","content":"This is a thorough analysis of diabetes dataset from Kaggle. In this article, I will demonstrate how to an end-to-end machine learning project using diverse classification models. In case you need the source data, visit this webpage: Data Source What Can We Do With This Dataset? The observations in the dataset are all females from Pima Indian heritage who are greater than or equal to 21 years old. Data Preprocessing I cannot emphasize the importance of data preprocessing. It is the process of transforming raw data into more reasonable, useful and efficient format. It's a must and one of the most important step in a machine learing project. Without it our models will probably crash and won't be able to generate good results. There are several steps in data preprocessing: data cleaning, data reduction and data transformation. In the following paragraphs, I'll show you how to perform the steps one by one. Data Cleaning # packages needed import numpy as np import pandas as pd # load data data = pd.read_csv('diabetes.csv') data.head(10) The meaning of each column is stated as below: Pregnancies: Number of times pregnant Glucose: Plasma glucose concentration a 2 hours in an oral glucose tolerance test BloodPressure: Diastolic blood pressure (mm Hg) SkinThickness: Triceps skin fold thickness (mm) Insulin: 2-Hour serum insulin (mu U/ml) BMI: Body mass index (weight in kg/(height in m)^2) DiabetesPedigreeFunction: Diabetes pedigree function Age: Age (years) Outcome: Class variable (0 or 1) Next, we need to examin whether there are null values in the dataset. data.isnull().sum() It seems there is no null values. Shall we pop the champagne now? If we further examine the data, we will find that the situation is not as good as we thought. data.describe() We can see from the picture above that the minimum value of Glucose, BloodPressure, SkinThickness, Insulin, BMI is zero. However, anyone having common sense knows that by no means would these indicators of an alive person be zero. Apparently, the null values are replaced by zeros when inputing data. Here we calculate the number of null values in each column so that we will better decide how to deal with them. for col in list(data.columns): zero = len(data[data[col] == 0]) print('0s in %s: %d' % (col, zero)) There are nearly 400 null values in Insulin column, so it's not realistic to drop all the null values. Normally under such circumstance, we replace them with indicators such as mean, median, or mode, etc. Here I choose median. # replace 0s in target columns with null value data.iloc[:, 1:6] = data.iloc[:, 1:6].replace({0:np.NaN}) # fill null values with medians data = data.fillna(data.median()) data.describe() Data Reduction With clean data at hand, we can visulize the data, which may indicate some relations between the features or between features and targets. import seaborn as sns sns.pairplot(data, hue=&quot;Outcome&quot;, corner=True) From the pair plot above, we see that there is not much difference in distribution between diabetics and nondiabetics except glucose. Data Transformation ","link":"https://qingqiuzhang.github.io/diabetes-dataset-report/"}]}